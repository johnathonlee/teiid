<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd" [
<!ENTITY % CustomDTD SYSTEM "../../../../../../docbook/custom.dtd">
%CustomDTD;
]>
<chapter id="performance">
	<title>Performance Tuning</title>
	<section id="memory_management">
		<title>Memory Management</title>
		<para>The BufferManager is responsible for tracking both memory and disk usage
			by Teiid. Configuring the BufferManager properly is one of the most
			important parts of ensuring high performance. See the &jboss-beans;
			file for all BufferManager settings.
		</para>
		<para>
			The Teiid engine uses batching to reduce the number of memory
			rows processed at a given time. The batch sizes may be adjusted to larger values if few clients will be
			accessing the Teiid server simultaneously.  
		</para>
		<para>
			The <code>maxReserveBatchColumns</code>
			setting determines the total size of batches that can be held by the BufferManager in memory.
			This number does not include persistent batches held by soft (such as
			index pages) or weak references. 
			The value is treated internally as an approximation of bytes using the conversion
			<code>maxReserveBatchColumns</code> * <code>processorBatchSize</code> * (64bytes per column value).
			The default value of -1 will auto-calculate a typical max based upon the max heap available to the VM.  
			The auto-calculated value assumes a 64bit architecture and will limit buffer usage to 50% of the first 
			gigabyte of memory beyond the first 300 megabytes (which are assumed for use by the AS and other Teiid purposes) 
			and 75% of the memory beyond that. 
		</para>
		<para>
		    The BufferManager automatically triggers the use of a canonical
			value cache if enabled when more than 25% of the reserve is in use.
			This can dramatically cut the memory usage in situations where similar
			value sets are being read through Teiid, but does introduce a lookup cost.
			If you are processing small or highly similar datasets 
			through Teiid, and wish to conserve memory, you should consider <link linkend="value_caching">enabling value caching</link>.
		</para>
		<note>
			<para>Memory consumption can be significantly more or less than the nominal target
	            depending upon actual column values and whether value caching is enabled.  Large strings, bigintegers, bigdecimals, or values typed as object can exceed their default size estimate.
	            If an out of memory errors occur, then set a lower the maxReserveBatchColumns value.
			</para>
		</note>
		<para>
			The <code>maxProcessingBatchesColumns</code>
			setting determines the total size of batches that can be used by active plans regardless of the memory held based on <code>maxReserveBatchColumns</code>.
			The value is treated internally as an approximation of bytes using the conversion
			<code>maxProcessingBatchesColumns</code> * <code>processorBatchSize</code> * (64bytes per column value).
			The default value of -1 will auto-calculate a typical max based upon the max heap available to the VM and max active plans.  
			The auto-calculated value assumes a 64bit architecture and will limit processing batch usage to 10% of memory 
			beyond the first 300 megabytes (which are assumed for use by the AS and other Teiid purposes).
		</para>
		<para>
			In systems where large intermediate results are normal (scrolling cursors or sorting over millions of rows) you can consider increasing the <code>maxProcessingBatchColumns</code> and decreasing
			the <code>maxReserveBatchColumns</code> so that each request has access to an effectively smaller buffer space.
		</para>
		<para>
			Each intermediate result buffer, temporary LOB, and temporary table
			is stored in its own set of buffer files,
			where an individual file is
			limited to <code>maxFileSize</code> megabytes.
			Consider increasing the storage space available to all such
			files <code>maxBufferSpace</code>
			if your installation makes use of internal materialization, makes
			heavy use of SQL/XML, or processes large row counts.
		</para>
	</section>
	<section>
		<title>Threading</title>
		<para>Socket threads are configured for each <link linkend="socket_transport">transport</link>.  
		They handle NIO non-blocking IO operations as well as directly servicing any operation that can run without blocking.
		For longer running operations, the socket threads queue with work the query engine.</para>
		
		<para>The query engine has several settings that determine its thread utilization.  
		
		<code>maxThreads</code> sets the total number of threads available for query engine work (processing plans, transaction control operations, processing source queries, etc.). 
		You should consider increasing the maximum threads on systems with a large number of available processors and/or when it's common to issue non-transactional queries with that 
		issue a large number of concurrent source requests.
		
		<code>maxActivePlans</code>, which should always be smaller than maxThreads, sets the number of the maxThreads 
		that should be used for user query processing.  Increasing the maxActivePlans should be considered for workloads with a high number of long 
		running queries and/or systems with a large number of available processors.  If memory issues arise from increasing the max threads and the
		max active plans, then consider decreasing the processor/connector batch sizes to limit the base number of memory rows consumed by each plan.
		
		<code>userRequestSourceConcurrency</code>, which should always be smaller than maxThreads, sets the number of concurrently executing source queries per user request.
		Setting this value to 1 forces serial execution of all source queries by the processing thread.  The default value is computed based upon 2*maxThreads/maxActivePlans. 
		Using the respective default values, this means that each user request would be allowed 6 concurrently executing source queries.  If the default calculated value is
		not applicable to your workload, for example if you have queries that generate more concurrent long running source queries, you should adjust this value.   
		</para>
	</section>
	<section>
		<title>Cache Tuning</title>
		<para>Caching can be tuned for cached result (including user query results and procedure results) and prepared plans (including user and stored procedure plans).  
		Even though it is possible to disable or otherwise severely constrain these caches, this would probably never be done in practice as it would lead to poor performance.
		</para><para>Cache statistics can be obtained through the Admin Console or Adminshell.  The statistics can be used to help tune cache parameters and ensure a hit ratio.</para>
		<para>Plans are currently fully held in memory and may have a significant memory footprint.  When making extensive use of prepared statements and/or virtual procedures, 
		the size of the plan cache may be increased proportionally to number of GB intended for use by Teiid.
		</para><para>While the result cache parameters control the cache result entries (max number, eviction, etc.), the result batches themselves are accessed through the <link linkend="memory_management">BufferManager</link>.
		If the size of the result cache is increased, you may need to tune the BufferManager configuration to ensure there is enough buffer space.
		</para>
	</section>
	<section id="socket_transport">
		<title>Socket Transports</title>
		<para>Teiid separates the configuration of its socket transports for
			JDBC, ODBC, and Admin access.
			Typical installations will not need to adjust the default thread and buffer size settings.
			The default input output buffer sizes are set to 0, which will use the system default.  
			Before adjusting this value keep in mind that each JDBC, ODBC, and Admin client will create a new socket connection.  
			Setting these values to a large buffer size should only be done if the number of client is constrained.
			All JDBC socket operations are non-blocking, so setting the number of maxThreads
			higher than the maximum effective parallelism of the machine should not result in greater performance.  
			The default value 0 for JDBC socket threads will set the max to the number of available processors.
			</para>
			<para>  
			At this time, ODBC queries are executed synchronously from the socket thread.
			Simultaneous long-running queries may exhaust the available threads.
			Consider increasing the default max threads (15) for ODBC if you
			expect a higher concurrent load of long-running ODBC client queries.</para>
	</section>
	<section>
		<title>LOBs</title>
		<para>LOBs and XML documents are streamed from the Teiid Server to the
			Teiid JDBC API.  
			Normally, these values are not materialized in the
			server memory - avoiding potential out-of-memory issues.
			When using style sheets, or XQuery, whole XML documents must be
			materialized on the server.
			Even when using the XMLQuery or XMLTable functions and
			document projection is applied, memory issues may occur for large
			documents.
		</para>
		<para>
			LOBs are broken into pieces when being created and streamed. 
			The maximum size of each piece when fetched by the client can be
			configured with the <code>"lobChunkSizeInKB"</code>
			property in the &jboss-beans; file. The default value is 100 KB.
			When dealing with extremely large LOBs, you may consider increasing this
			value to decrease the amount of round-trips to stream the result.
			Setting the value too high may cause the server or client to have
			memory issues.
		</para>
		<para>Source LOB values are typically accessed by reference, rather
			than having the value copied to a temporary location.
			Thus care must be taken to ensure that source LOBs are returned in a
			memory-safe manner.  
        </para>
	</section>
	<section>
		<title>Other Considerations</title>
		<para>When
			using Teiid in a development environment, you may consider setting
			the maxSourceRows property in the &jboss-beans;
			file to reasonably small level value (e.g. 10000) to prevent large
			amounts of data from being pulled from sources.
			Leaving the exceptionOnMaxSourceRows set to true will alert the developer
			through an exception that an attempt was made to retrieve more than
			the specified number of rows.
		</para>
	</section>
</chapter>